{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39938502",
   "metadata": {},
   "source": [
    "# KIBarDok Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c18804",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe1b4f",
   "metadata": {},
   "source": [
    "Importiere die Daten, projiziere die Texte auf die Nomen und lemmatisiere diese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50411629",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d537c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfeef019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print( spacy.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a837eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = spacy.load( 'de_dep_news_trf' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b80619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f5d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e41a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22.1\n"
     ]
    }
   ],
   "source": [
    "print( np.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35dddb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b47824",
   "metadata": {},
   "source": [
    "## Bereinige die Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525305dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text( text : str ) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    this function cleans the argument text by\n",
    "    - removing multiple white spaces\n",
    "    - removing \"\\\"\"\n",
    "    - removing everything but '[^a-zA-ZÄÖÜäöüß0-9 ]+'\n",
    "    - then, the text is split at \" \", and for each token, it is checked whether it only consists of uppercase letter.\n",
    "    If it does contain lowercase letters, it is broken at every uppercase letter\n",
    "    - tokens of length 1 and 2 are removed\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        text : str\n",
    "            a str object that is to be cleaned\n",
    "            \n",
    "    RETURNS\n",
    "    -------\n",
    "        ret : str\n",
    "            a str object of cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    ret = re.sub( '[^a-zA-ZÄÖÜäöüß0-9@+ ]+', ' ', text )\n",
    "    \n",
    "    ret = re.sub( ' +', ' ', ret )\n",
    "    \n",
    "    ret = ret.replace( \"\\\"\", \"\" )\n",
    "    \n",
    "    tokens = re.split( \" \", ret )\n",
    "    \n",
    "    list_of_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        \n",
    "        if token.upper() == token:\n",
    "            \n",
    "            list_of_tokens.append( token )\n",
    "            \n",
    "        elif token.lower() == token:\n",
    "            \n",
    "            list_of_tokens.append( token )\n",
    "            \n",
    "        elif ( token[ 0 ].upper == token[ 0 ] ) and ( token[ 1 : len( token ) ].lower() == token[ 1 : len( token ) ] ):\n",
    "            \n",
    "            list_of_tokens.append( token )\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if token[ 0 ].upper() == token[ 0 ]:\n",
    "                \n",
    "                new_tokens = re.findall( '[A-ZÄÖÜ][^A-ZÄÖÜ]*', token )\n",
    "                \n",
    "                for new_token in new_tokens:\n",
    "                    \n",
    "                    list_of_tokens.append( new_token )\n",
    "                    \n",
    "            else:\n",
    "                \n",
    "                first_token = re.split( \"[A-ZÄÖÜ]\", token )[ 0 ]\n",
    "                \n",
    "                list_of_tokens.append( first_token )\n",
    "                \n",
    "                additional_tokens = re.findall( '[A-ZÄÖÜ][^A-ZÄÖÜ]*', token )\n",
    "                \n",
    "                for additional_token in additional_tokens:\n",
    "                    \n",
    "                    list_of_tokens.append( additional_token )\n",
    "                    \n",
    "    ret = \"\"\n",
    "    \n",
    "    for token in list_of_tokens:\n",
    "        \n",
    "        ret += token + \" \"\n",
    "        \n",
    "    ret = ret[ 0 : len( ret ) - 1 ]\n",
    "                \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab43bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text( text : str ) -> list:\n",
    "    \n",
    "    \"\"\"\n",
    "    The tagger can only work with texts that have at most 512 tokens. Therefore, this function\n",
    "    splits a text into sequences of at most 512 tokens.\n",
    "    \n",
    "    Also, we ignore any token with length 2 or smaller.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        text : str\n",
    "            the text to be split\n",
    "            \n",
    "    RETURNS\n",
    "    -------\n",
    "        list_of_texts : list\n",
    "            a list of texts\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = text.split( \" \" )\n",
    "    \n",
    "    number_of_items = int( np.ceil( len( tokens ) / 512 ) )\n",
    "    \n",
    "    list_of_texts = []\n",
    "    \n",
    "    for i in range( number_of_items ):\n",
    "        \n",
    "        start = i * 512\n",
    "        \n",
    "        end = min( ( i + 1 ) * 512, len( tokens ) )\n",
    "        \n",
    "        sublist = tokens[ start : end ]\n",
    "        \n",
    "        text_in_sublist = \"\"\n",
    "        \n",
    "        for token in sublist:\n",
    "                \n",
    "            if len( token ) > 2:\n",
    "            \n",
    "                text_in_sublist += token + \" \"\n",
    "            \n",
    "        text_in_sublist = text_in_sublist[ 0 : len( text_in_sublist ) ]\n",
    "        \n",
    "        list_of_texts.append( text_in_sublist )\n",
    "            \n",
    "    return list_of_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90fcdc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text( text : str ) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions reduces a given text to a set of lemmatized nouns.\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        text : str\n",
    "            the text to be reduced\n",
    "            \n",
    "    RETURNS\n",
    "    -------\n",
    "        lemmatized : str\n",
    "            the lemmatized text\n",
    "    \"\"\"\n",
    "\n",
    "    only_nouns = \"\"\n",
    "    \n",
    "    list_of_texts = split_text( text )\n",
    "    \n",
    "    for item in list_of_texts:\n",
    "    \n",
    "        doc = tagger( re.sub( \"[^a-zA-ZÄÖÜäöüß ]\", \"\", item ) )\n",
    "    \n",
    "        for token in doc:\n",
    "            \n",
    "            word = token.lemma_\n",
    "        \n",
    "            if token.pos_ == \"NOUN\":\n",
    "            \n",
    "                only_nouns +=  word + \" \"\n",
    "            \n",
    "    only_nouns = only_nouns[ 0 : len( only_nouns ) - 1 ]\n",
    "    \n",
    "    return only_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96984c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_text( text : str ) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions reduces a dirty text to a set of lemmatized nouns\n",
    "    \n",
    "    PARAMETERS\n",
    "    ----------\n",
    "        text : str\n",
    "            the dirty text\n",
    "            \n",
    "    RETURNS\n",
    "    -------\n",
    "        clean : str\n",
    "            the cleaned text\n",
    "    \"\"\"\n",
    "    \n",
    "    return lemmatize_text( clean_text( text ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f689e0",
   "metadata": {},
   "source": [
    "Wende diese Bereinigung auf alle Texte an."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03debeca",
   "metadata": {},
   "source": [
    "## Importiere den Tf-Idf-Vektorizer und den Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca20e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tfidf = \"C:\\\\Users\\\\pinzir\\\\Desktop\\\\kibardok\\\\C Code\\\\tfidf.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6b045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_forest = \"C:\\\\Users\\\\pinzir\\\\Desktop\\\\kibardok\\\\C Code\\\\forest.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe61178",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( path_to_tfidf, \"rb\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e69cda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = pickle.load( file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a01e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5bb4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open( path_to_forest, \"rb\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a60c985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = pickle.load( file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1c061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13306630",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f754d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'BA Treptow-Köpenick von Berlin\\t\\nAbt. Bauen, Stadtentwicklung und Umwelt\\nStadtentwicklungsamt\\t\\nFachbereich Denkmalschutz\\t\\t\\n\\nFrau Töpfer\\nGrün II 3\\n\\n\\n\\n\\nGeschZ.\\t\\tBearbeiter/in\\t\\t\\tZimmer\\tTelefon\\tTelefax\\t\\t\\tDatum  \\n[bookmark: _GoBack]FB UD552-14\\t\\tFrau Marion Zeidler\\t\\t321\\t\\t90297-2191\\t90297-2195\\t\\t13.10.2014\\n\\n\\nBetr.: Grundstück: Treptower Park\\n\\nStellungnahmeersuchen vom: 13.10.12015\\nEingang: 14.10.2014 \\n\\nVorhaben: Baumfällung Ulmus BaumNr.20444 Parkteil B\\nIhr Zeichen: Grün II 3\\n\\n\\n\\n\\nDas Einvernehmen gemäß § 12 Abs. 3 DSchG Bln  wird in Verbindung mit § 11 Abs. 1 Denkmalschutzgesetz Berlin (DSchG Bln) vom 24.04.1995 (GVBl. 22 S. 274), zuletzt geändert durch Artikel II des Gesetzes vom 8. Juli 2010 (GVBl. S. 396) zu Baumfällung Ulmus BaumNr.204444 Parkteil B  erteilt.\\nA\\nGemäß § 11 Abs. 4 DSchG Bln kann die Genehmigung unter nachfolgend aufgeführten Bedingungen bzw. Auflagen sowie unter dem Vorbehalt des Widerrufs oder befristet erteilt werden.\\n\\n\\nAuflagen:\\n\\n- Nachpfllanzung \\n\\nBegründung\\n\\nI.  Sachverhalt\\n\\n\\n1. Genehmigungsbedürftigkeit\\n\\nDas beantragte Vorhaben  ist nach DSchG Bln genehmigungsbedürftig.\\n\\nNach § 11 Abs. 1 DSchG Bln darf ein Denkmal nur mit Genehmigung der zuständigen Denkmalbehörde in seinem Erscheinungsbild verändert, ganz oder teilweise beseitigt, von seinem Standort oder Aufbewahrungsort entfernt oder instandgesetzt und wiederhergestellt werden\\n\\nDie vom Antragsteller  beabsichtigte Baumfällungen\\nist eine Veränderung des Denkmals im Sinne von § 11 Abs. 1 Nr.  1  DSchG Bln und somit nach dem Denkmalschutzgesetz genehmigungspflichtig.\\n\\n\\n\\n2. Denkmaleigenschaft\\n\\n3. Genehmigungsfähigkeit\\n\\nDie Genehmigung kann gemäß § 11 Abs. 4 DSchG Bln unter Bedingungen und Auflagen sowie \\nunter dem Vorbehalt des Widerrufs oder befristet erteilt werden.\\n\\nDie denkmalrechtliche Genehmigung  zum o. g. Vorhaben wird unter Auflagen erteilt:\\n\\nAuflagen : Nachpflanzung in Abstimmung mit UD\\n\\nGemäß § 12 Abs. 2 DSchG Bln erlischt die Genehmigung, wenn nicht innerhalb von zwei Jahren nach Erteilung mit der Ausführung begonnen oder wenn die Ausführung ein Jahr unterbrochen worden ist. Die Fristen nach Satz 1 können auf schriftlichen Antrag jeweils bis zu einem Jahr verlängert werden.\\n\\nGemäß § 12 Abs. 3 DSchG Bln werden Genehmigungen, die auf Grund anderer Rechtsvorschriften erforderlich sind, durch die Erteilung auf Grund dieses Gesetzes nicht ersetzt.\\n\\n\\n\\n\\n\\nZeidler\\n\\n\\n\\n\\nSeite 1 - 2\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b526b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA Treptow-Köpenick von Berlin\t\n",
      "Abt. Bauen, Stadtentwicklung und Umwelt\n",
      "Stadtentwicklungsamt\t\n",
      "Fachbereich Denkmalschutz\t\t\n",
      "\n",
      "Frau Töpfer\n",
      "Grün II 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GeschZ.\t\tBearbeiter/in\t\t\tZimmer\tTelefon\tTelefax\t\t\tDatum  \n",
      "[bookmark: _GoBack]FB UD552-14\t\tFrau Marion Zeidler\t\t321\t\t90297-2191\t90297-2195\t\t13.10.2014\n",
      "\n",
      "\n",
      "Betr.: Grundstück: Treptower Park\n",
      "\n",
      "Stellungnahmeersuchen vom: 13.10.12015\n",
      "Eingang: 14.10.2014 \n",
      "\n",
      "Vorhaben: Baumfällung Ulmus BaumNr.20444 Parkteil B\n",
      "Ihr Zeichen: Grün II 3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Das Einvernehmen gemäß § 12 Abs. 3 DSchG Bln  wird in Verbindung mit § 11 Abs. 1 Denkmalschutzgesetz Berlin (DSchG Bln) vom 24.04.1995 (GVBl. 22 S. 274), zuletzt geändert durch Artikel II des Gesetzes vom 8. Juli 2010 (GVBl. S. 396) zu Baumfällung Ulmus BaumNr.204444 Parkteil B  erteilt.\n",
      "A\n",
      "Gemäß § 11 Abs. 4 DSchG Bln kann die Genehmigung unter nachfolgend aufgeführten Bedingungen bzw. Auflagen sowie unter dem Vorbehalt des Widerrufs oder befristet erteilt werden.\n",
      "\n",
      "\n",
      "Auflagen:\n",
      "\n",
      "- Nachpfllanzung \n",
      "\n",
      "Begründung\n",
      "\n",
      "I.  Sachverhalt\n",
      "\n",
      "\n",
      "1. Genehmigungsbedürftigkeit\n",
      "\n",
      "Das beantragte Vorhaben  ist nach DSchG Bln genehmigungsbedürftig.\n",
      "\n",
      "Nach § 11 Abs. 1 DSchG Bln darf ein Denkmal nur mit Genehmigung der zuständigen Denkmalbehörde in seinem Erscheinungsbild verändert, ganz oder teilweise beseitigt, von seinem Standort oder Aufbewahrungsort entfernt oder instandgesetzt und wiederhergestellt werden\n",
      "\n",
      "Die vom Antragsteller  beabsichtigte Baumfällungen\n",
      "ist eine Veränderung des Denkmals im Sinne von § 11 Abs. 1 Nr.  1  DSchG Bln und somit nach dem Denkmalschutzgesetz genehmigungspflichtig.\n",
      "\n",
      "\n",
      "\n",
      "2. Denkmaleigenschaft\n",
      "\n",
      "3. Genehmigungsfähigkeit\n",
      "\n",
      "Die Genehmigung kann gemäß § 11 Abs. 4 DSchG Bln unter Bedingungen und Auflagen sowie \n",
      "unter dem Vorbehalt des Widerrufs oder befristet erteilt werden.\n",
      "\n",
      "Die denkmalrechtliche Genehmigung  zum o. g. Vorhaben wird unter Auflagen erteilt:\n",
      "\n",
      "Auflagen : Nachpflanzung in Abstimmung mit UD\n",
      "\n",
      "Gemäß § 12 Abs. 2 DSchG Bln erlischt die Genehmigung, wenn nicht innerhalb von zwei Jahren nach Erteilung mit der Ausführung begonnen oder wenn die Ausführung ein Jahr unterbrochen worden ist. Die Fristen nach Satz 1 können auf schriftlichen Antrag jeweils bis zu einem Jahr verlängert werden.\n",
      "\n",
      "Gemäß § 12 Abs. 3 DSchG Bln werden Genehmigungen, die auf Grund anderer Rechtsvorschriften erforderlich sind, durch die Erteilung auf Grund dieses Gesetzes nicht ersetzt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Zeidler\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Seite 1 - 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a287409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pinzir\\Anaconda3\\envs\\KIBarDok\\lib\\site-packages\\torch\\autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.predict( vectorizer.transform( [ lemmatize_text( clean_text( text ) ) ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003208a1",
   "metadata": {},
   "source": [
    "## Dokumenttypen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c55ccd",
   "metadata": {},
   "source": [
    "Es gibt folgende Dokumenttypen:\n",
    "* 0 kein Dokumenttyp gefunden\n",
    "* 1 Genehmigung\n",
    "* 2 Stellungnahme\n",
    "* 3 Anfrage\n",
    "* 4 Nachforderung\n",
    "* 5 Eingang\n",
    "* 6 Versagung\n",
    "* 7 Antrag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
