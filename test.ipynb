{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import gensim\r\n",
    "import gensim.corpora as corpora\r\n",
    "from gensim.utils import simple_preprocess\r\n",
    "from gensim.models import CoherenceModel\r\n",
    "\r\n",
    "from gensim.parsing.preprocessing import preprocess_string\r\n",
    "import spacy\r\n",
    "from typing import Dict, Any, List, Tuple\r\n",
    "from pprint import pprint\r\n",
    "import pymongo\r\n",
    "# Plotting tools\r\n",
    "import pyLDAvis\r\n",
    "import pyLDAvis.gensim_models  # don't skip this\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "# %matplotlib inline\r\n",
    "\r\n",
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\r\n",
    "\r\n",
    "nlp = None\r\n",
    "\r\n",
    "\r\n",
    "def split_in_sentences(text: str) -> List[str]:\r\n",
    "    doc = spacy_nlp(text)\r\n",
    "    return [str(sent).strip() for sent in doc.sents]\r\n",
    "\r\n",
    "\r\n",
    "def remove_stopwords(word: str) -> str:\r\n",
    "    word = word.replace(\"(\", \" \")\r\n",
    "    word = word.replace(\")\", \" \")\r\n",
    "    word = word.replace(\"/\", \" \")\r\n",
    "    word = word.replace(\"II\", \" \")\r\n",
    "    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\r\n",
    "    wl = spacy_nlp(word)\r\n",
    "    tokens = [word for word in wl if not word.is_stop and word.pos_ in allowed_postags]\r\n",
    "    return \" \".join(str(x) for x in tokens), tokens\r\n",
    "\r\n",
    "\r\n",
    "def spacy_nlp(x: str):\r\n",
    "    global nlp\r\n",
    "    if nlp == None:\r\n",
    "        nlp = spacy.load(\"de_core_news_md\")\r\n",
    "        nlp.disable_pipe(\"ner\")\r\n",
    "        nlp.disable_pipe(\"attribute_ruler\")\r\n",
    "        nlp.add_pipe('sentencizer')\r\n",
    "\r\n",
    "    y = nlp(x)\r\n",
    "    return y\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Data\\test\\semkibardoc\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# def make_bigrams(texts):\r\n",
    "#     return [bigram_mod[doc] for doc in texts]\r\n",
    "\r\n",
    "# def make_trigrams(texts):\r\n",
    "#     return [trigram_mod[bigram_mod[doc]] for doc in texts]\r\n",
    "\r\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\r\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\r\n",
    "    texts_out = []\r\n",
    "    for sent in texts:\r\n",
    "        doc = spacy_nlp(\" \".join(sent)) \r\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\r\n",
    "    return texts_out\r\n",
    "\r\n",
    "def tm_test(docs: any):\r\n",
    "    data_words= []\r\n",
    "    allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']\r\n",
    "    for doc in docs:\r\n",
    "        txt = doc[\"text\"]\r\n",
    "        txt = txt.replace(\"\\n\", \" \")\r\n",
    "        paragraphs: List[str] = split_in_sentences(txt)\r\n",
    "        for p in paragraphs:\r\n",
    "            pt, ignore = remove_stopwords(p)\r\n",
    "            p = preprocess_string(pt)\r\n",
    "            if len(p)>0:\r\n",
    "                data_words.append(list(p))\r\n",
    "            # print(data_words)\r\n",
    "\r\n",
    "    # print(data_words)\r\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=10)\r\n",
    "    trigram = gensim.models.Phrases(bigram[data_words], threshold=10)\r\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\r\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\r\n",
    "    # print(bigram_mod)\r\n",
    "    # print(trigram_mod)\r\n",
    "\r\n",
    "    data_words_bigrams = [bigram_mod[doc] for doc in data_words]\r\n",
    "    data_lemmatized = data_words_bigrams\r\n",
    "\r\n",
    "    id2word = corpora.Dictionary(data_lemmatized)\r\n",
    "    corpus = [id2word.doc2bow(text) for text in data_lemmatized]\r\n",
    "    # print(corpus[:1])\r\n",
    "    # print([[(id2word[id], freq) for id, freq in cp] for cp in corpus[0:10]])\r\n",
    "\r\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\r\n",
    "                                           id2word=id2word,\r\n",
    "                                           num_topics=20, \r\n",
    "                                           random_state=100,\r\n",
    "                                           update_every=1,\r\n",
    "                                           chunksize=100,\r\n",
    "                                           passes=10,\r\n",
    "                                           alpha='auto',\r\n",
    "                                           per_word_topics=True)\r\n",
    "\r\n",
    "    print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\r\n",
    "\r\n",
    "    # coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\r\n",
    "    # coherence_lda = coherence_model_lda.get_coherence()\r\n",
    "    # print('\\nCoherence Score: ', coherence_lda)                                   \r\n",
    "\r\n",
    "    pprint(lda_model.print_topics())    \r\n",
    "    pyLDAvis.enable_notebook()\r\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\r\n",
    "    vis\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Data\\test\\semkibardoc\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def extractDocs():\r\n",
    "    # uri1 = os.getenv(\"MONGO_CONNECTION\")\r\n",
    "    # uri1 = \"mongodb://localhost:27017\"\r\n",
    "    uri1 = \"mongodb+srv://klsuser:Kb.JHQ-.HrCs6Fw@cluster0.7qi8s.mongodb.net/test?authSource=admin&replicaSet=atlas-o1jpuq-shard-0&readPreference=primary&appname=MongoDB%20Compass&ssl=true\"\r\n",
    "\r\n",
    "    myclient = pymongo.MongoClient(uri1)\r\n",
    "    # myclient._topology_settings\r\n",
    "\r\n",
    "    mydb = myclient[\"kibardoc\"]\r\n",
    "    \r\n",
    "    samples = mydb[\"samples\"]\r\n",
    "    # extractText(\"C:\\\\Data\\\\test\\\\topics\",\r\n",
    "    #             samples, \"http://localhost:9998\")\r\n",
    "    texts = []\r\n",
    "    # for s in samples.find({\"path\": \"C:\\\\Data\\\\test\\\\topics\\\\baumfällung\"})[:]:\r\n",
    "    #     texts.append(s)\r\n",
    "    # for s in samples.find({\"path\": \"C:\\\\Data\\\\test\\\\topics\\\\werbung\"})[:]:\r\n",
    "    #     texts.append(s)\r\n",
    "    for s in samples.find({\"path\": \"C:\\\\Data\\\\test\\\\topics\\\\fenster\"})[:]:\r\n",
    "        texts.append(s)\r\n",
    "    tm_test(texts)\r\n",
    "\r\n",
    "extractDocs()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Data\\test\\semkibardoc\\.venv\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Perplexity:  -24.91640243005216\n",
      "[(0,\n",
      "  '0.030*\"ausgetauscht\" + 0.022*\"nehmen\" + 0.021*\"thema\" + 0.019*\"weg\" + '\n",
      "  '0.016*\"substanz\" + 0.010*\"krefeld\" + 0.000*\"holzfenst\" + 0.000*\"finden\" + '\n",
      "  '0.000*\"gangbaren\" + 0.000*\"fassadengestaltung\"'),\n",
      " (1,\n",
      "  '0.692*\"fenster\" + 0.059*\"historisch\" + 0.025*\"erhalten\" + 0.013*\"lassen\" + '\n",
      "  '0.011*\"einbruchschutz\" + 0.007*\"stand\" + 0.006*\"wartung\" + '\n",
      "  '0.002*\"gleichzeitig\" + 0.002*\"handwerklich\" + 0.000*\"verlust\"'),\n",
      " (2,\n",
      "  '0.326*\"fensterbau\" + 0.068*\"wert\" + 0.056*\"fenstern\" + 0.025*\"kosten\" + '\n",
      "  '0.016*\"schäden\" + 0.015*\"denkmalgerecht\" + 0.012*\"energetisch\" + '\n",
      "  '0.006*\"historischen_fenstern\" + 0.003*\"erkennen\" + 0.000*\"rung\"'),\n",
      " (3,\n",
      "  '0.009*\"beitrag\" + 0.007*\"hierzu\" + 0.002*\"interess\" + 0.001*\"mal\" + '\n",
      "  '0.000*\"fest\" + 0.000*\"beispielsweis\" + 0.000*\"regen\" + 0.000*\"widerspruch\" '\n",
      "  '+ 0.000*\"direkten\" + 0.000*\"notwendigkeit\"'),\n",
      " (4,\n",
      "  '0.000*\"preisbeispielen\" + 0.000*\"abm\" + 0.000*\"dekorationsprofil\" + '\n",
      "  '0.000*\"standardmäßig\" + 0.000*\"wartungshinweis\" + 0.000*\"designvorschlägen\" '\n",
      "  '+ 0.000*\"deko\" + 0.000*\"wunschfenst\" + 0.000*\"konfigurieren\" + '\n",
      "  '0.000*\"lasurfarben\"'),\n",
      " (5,\n",
      "  '0.023*\"frage\" + 0.007*\"augen\" + 0.003*\"verseidag\" + 0.002*\"äußer\" + '\n",
      "  '0.000*\"www_daemmen\" + 0.000*\"und_sanieren\" + 0.000*\"stellen\" + '\n",
      "  '0.000*\"verglasung\" + 0.000*\"beschläg\" + 0.000*\"haus\"'),\n",
      " (6,\n",
      "  '0.043*\"steht\" + 0.042*\"baudenkm\" + 0.042*\"element\" + 0.015*\"bauteil\" + '\n",
      "  '0.002*\"erhaltung\" + 0.000*\"fenster_baudenkm\" + 0.000*\"www\" + '\n",
      "  '0.000*\"fluchtfenst\" + 0.000*\"beachten\" + 0.000*\"holzfenst\"'),\n",
      " (7,\n",
      "  '0.557*\"denkmalschutz\" + 0.031*\"austausch\" + 0.009*\"weis\" + 0.007*\"bewahren\" '\n",
      "  '+ 0.001*\"erfolgreich\" + 0.000*\"holzfenst\" + 0.000*\"www_ventano\" + '\n",
      "  '0.000*\"http\" + 0.000*\"http_www\" + 0.000*\"reheus_denkmalschutzfenst\"'),\n",
      " (8,\n",
      "  '0.017*\"pflege\" + 0.013*\"neubau\" + 0.007*\"statisch\" + 0.006*\"instandsetzung\" '\n",
      "  '+ 0.006*\"reparatur\" + 0.003*\"ähnlich\" + 0.002*\"hinsicht\" + 0.001*\"dokument\" '\n",
      "  '+ 0.001*\"fensterflügel\" + 0.001*\"gestalterisch\"'),\n",
      " (9,\n",
      "  '0.034*\"verschieden\" + 0.021*\"ansprüchen\" + 0.017*\"art\" + 0.013*\"flügel\" + '\n",
      "  '0.013*\"herstellung\" + 0.009*\"kipp\" + 0.007*\"verloren\" + 0.004*\"rohe\" + '\n",
      "  '0.003*\"entwickelt\" + 0.001*\"lauf\"'),\n",
      " (10,\n",
      "  '0.138*\"gebäud\" + 0.037*\"erhalt\" + 0.029*\"erscheinungsbild\" + '\n",
      "  '0.024*\"bedeutung\" + 0.005*\"prägen\" + 0.002*\"wesentlich\" + '\n",
      "  '0.001*\"tatsächlich\" + 0.001*\"farbigkeit\" + 0.000*\"historischen\" + '\n",
      "  '0.000*\"kulturhistorisch\"'),\n",
      " (11,\n",
      "  '0.067*\"informationen\" + 0.042*\"wichtig\" + 0.034*\"restaurierung\" + '\n",
      "  '0.016*\"heutigen\" + 0.014*\"standard\" + 0.006*\"stahlfenst\" + '\n",
      "  '0.006*\"dokumentieren\" + 0.006*\"jeweiligen\" + 0.004*\"bauten\" + '\n",
      "  '0.004*\"möglichkeiten\"'),\n",
      " (12,\n",
      "  '0.030*\"technisch\" + 0.015*\"entsprechend\" + 0.014*\"konstrukt\" + '\n",
      "  '0.013*\"bestimmt\" + 0.002*\"jeweil\" + 0.001*\"veränderungen\" + '\n",
      "  '0.000*\"bestandsfenstern\" + 0.000*\"dekorationsprofil\" + 0.000*\"entspr\" + '\n",
      "  '0.000*\"enthalten\"'),\n",
      " (13,\n",
      "  '0.045*\"hohen\" + 0.042*\"verwendet\" + 0.039*\"hau\" + 0.038*\"alten\" + '\n",
      "  '0.027*\"gla\" + 0.023*\"gern\" + 0.015*\"möglichkeit\" + 0.013*\"entwicklung\" + '\n",
      "  '0.012*\"architekten\" + 0.008*\"eigenschaften\"'),\n",
      " (14,\n",
      "  '0.057*\"denkmalpfleg\" + 0.027*\"foto\" + 0.002*\"lvr_amt\" + '\n",
      "  '0.000*\"tischler_fap\" + 0.000*\"http_www\" + 0.000*\"sprossen\" + '\n",
      "  '0.000*\"unser_programm\" + 0.000*\"mit\" + 0.000*\"der\" + '\n",
      "  '0.000*\"fenster_baudenkm\"'),\n",
      " (15,\n",
      "  '0.035*\"einfach\" + 0.019*\"gebäuden\" + 0.012*\"traditionel\" + 0.006*\"behalten\" '\n",
      "  '+ 0.002*\"parallel\" + 0.001*\"tern\" + 0.000*\"holzfenst\" + 0.000*\"eingebaut\" + '\n",
      "  '0.000*\"objektbau\" + 0.000*\"holztüren\"'),\n",
      " (16,\n",
      "  '0.031*\"gestaltung\" + 0.011*\"fassad\" + 0.002*\"schen\" + 0.001*\"bedeutend\" + '\n",
      "  '0.000*\"künstlerischen\" + 0.000*\"originalen\" + 0.000*\"holz\" + 0.000*\"nah\" + '\n",
      "  '0.000*\"denkmalschutzfenst\" + 0.000*\"farbgebung\"'),\n",
      " (17,\n",
      "  '0.040*\"schallschutz\" + 0.024*\"architektur\" + 0.012*\"baudenkmäl\" + '\n",
      "  '0.011*\"dienen\" + 0.010*\"besitzen\" + 0.009*\"gehören\" + 0.002*\"denkmälern\" + '\n",
      "  '0.001*\"institut\" + 0.001*\"baugeschicht\" + 0.000*\"holzfenst\"'),\n",
      " (18,\n",
      "  '0.000*\"preisbeispielen\" + 0.000*\"abm\" + 0.000*\"dekorationsprofil\" + '\n",
      "  '0.000*\"standardmäßig\" + 0.000*\"wartungshinweis\" + 0.000*\"designvorschlägen\" '\n",
      "  '+ 0.000*\"deko\" + 0.000*\"wunschfenst\" + 0.000*\"konfigurieren\" + '\n",
      "  '0.000*\"lasurfarben\"'),\n",
      " (19,\n",
      "  '0.029*\"wärmedämmung\" + 0.028*\"dichtigkeit\" + 0.022*\"blick\" + '\n",
      "  '0.014*\"technischen\" + 0.006*\"entwicklungen\" + 0.005*\"ziel\" + '\n",
      "  '0.001*\"dokumentiert\" + 0.000*\"vorteil\" + 0.000*\"denkmalfenst\" + '\n",
      "  '0.000*\"reheus\"')]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "ff37d9d1942c2185fb6eff70f5f0061ce011658d68aecddc2ee5b83915aa0722"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}